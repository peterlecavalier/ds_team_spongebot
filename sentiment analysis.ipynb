{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Sentiment Analysis modified from LING 3832 Assignment</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalised classifier using Naive Baye's (for now only using basic positive/negative classes)\n",
    "\n",
    "* positive: `this is good`\n",
    "* positive: `this could be great`\n",
    "* negative: `this is not good`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data in dictionaries where  key = class\n",
    "corpus = {}\n",
    "corpus['pos'] = [\"this is good\", \"this could be great\"]\n",
    "corpus['neg'] = [\"this is not good\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store counts of each word in 'pos' and 'neg' using dictionaries again, function that calculates probability of a word belonging to a class, implement smoothing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {}        # collect word counts in a dictionary of dictionaries\n",
    "vocabulary = set() # store all the words used in a set\n",
    "\n",
    "for c in corpus.keys():           # loop over sentiment classes\n",
    "    counts[c] = {}                # create a counts dictionary for each class\n",
    "\n",
    "\n",
    "# loop over classes, sentences, and words to add each word to the vocab set    \n",
    "# for c in corpus.keys():\n",
    "#     for text in corpus[c]:\n",
    "#         for w in text.split():\n",
    "#             vocabulary.add(w)\n",
    "# more succint set comprehension:\n",
    "vocabulary = {w for c in corpus.keys() for text in corpus[c] for w in text.split()}\n",
    "\n",
    "# Set counts to zero in all classes\n",
    "for word in vocabulary:\n",
    "    for c in corpus.keys():\n",
    "        counts[c][word] = 0\n",
    "    \n",
    "# create counts in the counts dictionaries\n",
    "for c in corpus.keys():                     # each class\n",
    "    for text in corpus[c]:                  # each sentence\n",
    "        for w in text.split():              # each word/sentence\n",
    "            counts[c][w] = counts[c][w] + 1 # +1 to count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'be', 'could', 'good', 'great', 'is', 'not', 'this'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos': {'not': 0,\n",
       "  'great': 1,\n",
       "  'good': 1,\n",
       "  'is': 1,\n",
       "  'be': 1,\n",
       "  'could': 1,\n",
       "  'this': 2},\n",
       " 'neg': {'not': 1,\n",
       "  'great': 0,\n",
       "  'good': 1,\n",
       "  'is': 1,\n",
       "  'be': 0,\n",
       "  'could': 0,\n",
       "  'this': 1}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store sum total counts in each class in a totals dictionary\n",
    "totals = {}\n",
    "for c in corpus.keys():\n",
    "    totals[c] = sum(counts[c].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos': 7, 'neg': 4}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function that returns the probability of given word in given class:  \n",
    "smoothing applied with parameter of pseudocounts 'alpha'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getprob(word, cl, countdict, totalsdict, vocabset, alpha):\n",
    "    return (countdict[cl][word] + alpha)/(totalsdict[cl] + len(vocabset) * alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21428571428571427"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "getprob('this', 'pos', counts, totals, vocabulary, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test analysis\n",
    "test = 'this is not great'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loop over each word in test sentence and multiply probabilities together from the pos and neg dictionaries, determine which class results in greater probablity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The likelihood of the text:  this is not great   being in pos is 0.00020824656393169508\n",
      "The likelihood of the text:  this is not great   being in neg is 0.00018213692143068556\n"
     ]
    }
   ],
   "source": [
    "numdocuments = sum(len(corpus[c]) for c in corpus.keys())\n",
    "prev = {}\n",
    "for c in corpus.keys():\n",
    "    prev[c] = len(corpus[c])/numdocuments\n",
    "\n",
    "for c in corpus.keys():\n",
    "    p = prev[c] # Set p to the prev\n",
    "    for w in test.split():\n",
    "        p = p * getprob(w, c, counts, totals, vocabulary, 1.0)\n",
    "    print(\"The likelihood of the text: \", test, \"  being in\", c, \"is\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same strategy using sum of log probabilities (above method returns small vals close to 0 for longer sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log likelihood of the text:  this is not great   being in pos is -8.4767877767812\n",
      "The log likelihood of the text:  this is not great   being in neg is -8.610751838181756\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "for c in corpus.keys():\n",
    "    p = math.log(prev[c]) # Set p to the prior\n",
    "    for w in test.split():\n",
    "        p = p + math.log(getprob(w, c, counts, totals, vocabulary, 1.0))\n",
    "    print(\"The log likelihood of the text: \", test, \"  being in\", c, \"is\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conclusion:  \n",
    "probability analysis returns that the sentence is slightly more likely to be positive, which is not correct but could be improved by weighting the positivity/negativity of each word in the vocab?  \n",
    "also could be due to limited training data and when applied to larger corpora might perform more accurately?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "71580fde4aa79eda6587ee9f80f0c796c45ca7449b7b244ff97eb5a6f26a1de3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
